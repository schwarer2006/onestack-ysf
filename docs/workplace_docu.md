# ğŸ§  OneStack YSF â€“ YAML Semantic Framework

OneStack dient als modulare, YAML-gesteuerte DatenlÃ¶sung.

---

## ğŸ”§ YSF Core Komponenten

### ğŸ§  OneStack YSF Modeler *(neu)*
Ziel: Modellierungs- & Semantik-Layer  
Tools: WebGUI + CLI  
Verantwortlich fÃ¼r:
- Dimensionen & Fakten designen
- SCD2/Surrogate Keys verwalten
- Keys & Relationships visualisieren
- Gold Layer aufbauen (dim/fact views)
- Semantic Layer fÃ¼r Metabase
- Measures & Aggregationen verwalten (optional)

---

### ğŸ”„ OneStack YSF Loader *(besteht schon)*
Ziel: Operational ETL Layer  
Tools: CLI + Web + TUI  
Verantwortlich fÃ¼r:
- Laden, Umwandeln, Bereinigen
- Datei-Handling (in â†’ out â†’ history)
- View-Erzeugung
- Laden in DuckDB/PostgreSQL
- Logging, Monitoring
- Transformation Ã¼ber YAML

---

## âš™ï¸ YSF Runner (Job Execution)

---

## ğŸª™ Bronze â†’ Silver â†’ Gold Layer Konzept

| Schicht | Beschreibung |
|--------|--------------|
| Bronze | Rohdaten (CSV, Parquet) |
| Silver | Bereinigt und verbunden |
| Gold   | Auswertbare Modelle in PostgreSQL fÃ¼r DWH & Metabase |

---

## ğŸ§± Module nach Schicht

| Ebene   | Modul         | Aufgabe |
|---------|---------------|---------|
| Quelle  | YSF Loader    | Rohdaten holen, speichern |
| Bronze  | YSF Processor | Bereinigen, typisieren |
| Silver  | YSF Transformer | Joins, Businesslogik, SCD2 |
| Gold    | YSF Publisher | Export nach PostgreSQL, Views |

---

## ğŸ“„ YAML Layer: Beispiel Customer

| Schicht | Datei                     | Typ         | Beschreibung |
|---------|---------------------------|-------------|--------------|
| 1       | customer_loader.yaml      | source      | Quelle & Encoding |
| 2       | customer_bronze.yaml      | raw         | Aufnahme in Parquet (in/) |
| 3       | customers.yaml            | dimension   | SCD2, Hashes, Normalisierung |
| 4       | dim_customer.yaml         | dim_export  | Mapping nach PostgreSQL |
| 5       | customer_snapshot.yaml    | snapshot    | Historie (optional) |
| 6       | customer_metrics.yaml     | measure     | KPIs fÃ¼r BI (optional) |

---

## ğŸ§  Warum Trennung ab Loader wichtig ist:

- **Fakten** sind transaktional, oft append-only
- **Dimensionen** haben SCD2, Surrogate Keys
- Unterschiedliche QualitÃ¤tsprÃ¼fungen

---

## âœ… Kern-Typen in OneStack YSF

| Typ          | Zweck                                   | Kategorie         |
|--------------|------------------------------------------|-------------------|
| source       | CSV, API, JSON etc.                      | ğŸ”„ Loader         |
| dimension    | Stammdaten mit SCD/SID                  | ğŸ§± Modell         |
| fact         | Bewegungs-/Transaktionsdaten            | ğŸ§± Modell         |
| measure      | KPIs, Kennzahlen                        | ğŸ“Š Reporting      |
| snapshot     | Zustand zu Zeitpunkten                  | ğŸ•“ Historie       |
| dim_export   | Export der Dimensionen                  | ğŸ Deployment     |
| fact_export  | Export der Fakten                       | ğŸ Deployment     |

---

## ğŸ”§ Erweiterbare Typen (optional)

- `lookup`, `bridge`, `hierarchy`, `audit`
- `cdc_stream`, `calculation`, `template`, `test`, `view`, `aggregation`, `staging`

---

## ğŸšš Ladearten (`load_type` Ãœbersicht)

| Typ        | Beschreibung                        | Besonderheit |
|------------|-------------------------------------|--------------|
| initial    | Erster kompletter Load              | lÃ¶scht ggf. Ziel |
| full       | Volllast bei jedem Lauf             | teuer bei viel Daten |
| delta      | Ã„nderungen anhand Hash/ID erkennen  | Vergleich nÃ¶tig |
| incremental| Zeitbasierte ErgÃ¤nzungen            | braucht Timestamp |
| cdc        | Echtzeit-Ã„nderungen (Insert/Update/Delete) | braucht CDC-Quelle |
| append     | Nur neue DatensÃ¤tze hinzufÃ¼gen      | keine PrÃ¼fung |
| partial    | Teilimport (z.â€¯B. pro Monat)        | Filter nÃ¶tig |
| reload     | Manuelles Neuladen                  | Recovery |
| streaming  | Kontinuierlich (z.â€¯B. Kafka)        | komplex |
| manual     | Nur manuell ausgefÃ¼hrt              | kein Trigger |

---

## ğŸ§° PostgreSQL als DWH-Ziel

- Star-Schema: `dim_customer`, `fact_sales`
- Materialisierte Views
- Indexe, Partitionierung
- Cron-Jobs / ETL via OneStack
- DB-Tests: Not Null, dbt-kompatibel

---

## ğŸ“¦ Warum Parquet?

| Vorteil                  | Beschreibung |
|--------------------------|--------------|
| Spaltenbasiert           | Schnell bei SELECT |
| Komprimiert              | Wenig Speicher |
| Direkt in DuckDB nutzbar | Ohne Import |
| Tool-Ã¼bergreifend        | Kompatibel mit Pandas, Spark etc. |
| Metadaten speicherbar    | UUID, Layer etc. |
| Versionierbar            | Snapshots mit Zeitstempel |
| Ideal fÃ¼r Data Lineage   | Klarer Datenfluss in Pfadstruktur |

---

## ğŸ” Parquet im Einsatz

- `YSF Loader`: aus CSV â†’ Parquet (`/in`)
- `YSF Processor`: Transformation â†’ Parquet (`/out`)
- `YSF Exporter`: nach PostgreSQL schreiben
- `Snapshots`: Archivdateien

---

## ğŸ§  Module & Zusatzkomponenten

### ğŸ”§ YSF Core

| Modul         | Aufgabe |
|---------------|---------|
| YSF Loader    | Quelle lesen, Parquet schreiben |
| YSF Processor | Transformieren, bereinigen |
| YSF Exporter  | Export zu PostgreSQL |
| YSF Snapshot  | Zeitpunkt sichern |
| YSF Metrics   | KPI-Berechnung |

### â± Orchestrierung

| Modul              | Aufgabe |
|--------------------|---------|
| YSF Job Runner     | FÃ¼hrt einzelne Jobs aus |
| YSF Scheduler      | Cron/Trigger basiert |
| YSF DAG Orchestrator | Kettung von Jobs |
| YSF Parameter Store | Zentrale Konfiguration |
